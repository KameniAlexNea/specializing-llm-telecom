{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/eak/learning/llm_finetuning/specializing-llm-telecom\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from peft import PeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
      "   \\\\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.438 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.1+cu118. CUDA = 8.6. CUDA Toolkit = 11.8.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1+cu118. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "\n",
    "result: tuple[PeftModelForCausalLM, AutoTokenizer] = FastLanguageModel.from_pretrained(\n",
    "\tmodel_name = \"data/models/checkpoint-3750\",\n",
    "\tmax_seq_length = max_seq_length,\n",
    "\tdtype = dtype,\n",
    "\tload_in_4bit = load_in_4bit,\n",
    "\t# token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")\n",
    "model: PeftModelForCausalLM = result[0]\n",
    "tokenizer: AutoTokenizer = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def create_dataset(data: dict):\n",
    "\tdef patch_raw(raw: dict):\n",
    "\t\tfor i in range(2, 6):\n",
    "\t\t\traw[f\"option {i}\"] = raw.get(f\"option {i}\")\n",
    "\t\treturn raw\n",
    "\tdata_pashed = [\n",
    "\t\tpatch_raw(raw) for raw in data.values()\n",
    "\t]\n",
    "\tdata_pashed = Dataset.from_list(data_pashed)\n",
    "\treturn data_pashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1461"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = json.load(open(\"data/zindi_data/TeleQnA_training.json\"))\n",
    "training_ds = create_dataset(training)\n",
    "\n",
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca_prompt = Copied from above\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I need you to choose the correct answer from a multiple-choice question. \n",
    "The question will have several options labeled with letters. There is always one correct answer among the choices. \n",
    "Please provide both the letter and the corresponding answer. \n",
    "Only generate the answer without any additional text.\n",
    "\"\"\"\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Inputs:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "OPTIONS = [f\"option {i}\" for i in range(1, 6)]\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples: dict[str, str]):\n",
    "\tdef apply_one(question,category, *options):\n",
    "\t\tinstructions = f\"Domain: {category}:\\n{question}\"\n",
    "\t\tinputs       = \"\\n\".join([f\"option {i}: \" + text for i, text in enumerate(options, start=1) if text is not None]) #  \n",
    "\t\toutputs      = \"\"\n",
    "\t\treturn alpaca_prompt.format(instructions, inputs, outputs)\n",
    "\ttexts = [apply_one(question, category, *options) for question, category, *options in zip(\n",
    "\t\texamples[\"question\"], examples[\"category\"],  examples['option 1'], examples['option 2'], examples['option 3'], examples['option 4'], examples['option 5']\n",
    "\t)]\n",
    "\treturn { \"text\" : texts, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e5769b1f8f40c48fc24986756eb826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1461 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_ds = training_ds.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nWhat is the purpose of the Nmfaf_3daDataManagement_Deconfigure service operation? [3GPP Release 18]\\n\\n### Inputs:\\noption 1: To configure the MFAF to map data or analytics received by the MFAF to out-bound notification endpoints\\noption 2: To configure the MFAF to stop mapping data or analytics received by the MFAF to out-bound notification endpoints\\noption 3: To supply data or analytics from the MFAF to notification endpoints\\noption 4: To fetch data or analytics from the MFAF based on fetch instructions\\n\\n### Response:\\n',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nHow does a supporting UE attach to the same core network operator from which it detached in a shared network? [3GPP Release 17]\\n\\n### Inputs:\\noption 1: It requests the core network node to remember its previous selection.\\noption 2: It uses information stored in the UE when it was detached.\\noption 3: It relies on the SIM/USIM card for information.\\noption 4: It performs a fresh attach procedure.\\n\\n### Response:\\n',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nWhen can the setting of the Privacy exception list be changed? [3GPP Release 17]\\n\\n### Inputs:\\noption 1: Never\\noption 2: Only during emergency services\\noption 3: Anytime\\noption 4: Only with operator permission\\n\\n### Response:\\n',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nWhat does the NEF notify to the AF after determining the suitable DNAI(s)? [3GPP Release 18]\\n\\n### Inputs:\\noption 1: AF Identifier\\noption 2: EAS address information\\noption 3: DNN\\noption 4: DNAI(s) or the updated DNAI information\\n\\n### Response:\\n',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nIn online charging, how are chargeable events transformed into charging events? [3GPP Release 18]\\n\\n### Inputs:\\noption 1: By the CTF\\noption 2: By the OCF\\noption 3: By the CGF\\noption 4: By the CHF\\n\\n### Response:\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds[:5][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "training_ds[:1][\"text\"], return_tensors = \"pt\", padding=True, truncation=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ['What is the purpose of the Nmfaf_3daDataManagement_Deconfigure service operation? [3GPP Release 18]'],\n",
       " 'option 1': ['To configure the MFAF to map data or analytics received by the MFAF to out-bound notification endpoints'],\n",
       " 'option 2': ['To configure the MFAF to stop mapping data or analytics received by the MFAF to out-bound notification endpoints'],\n",
       " 'option 3': ['To supply data or analytics from the MFAF to notification endpoints'],\n",
       " 'option 4': ['To fetch data or analytics from the MFAF based on fetch instructions'],\n",
       " 'answer': ['option 2: To configure the MFAF to stop mapping data or analytics received by the MFAF to out-bound notification endpoints'],\n",
       " 'explanation': ['The Nmfaf_3daDataManagement_Deconfigure service operation is used to stop mapping data or analytics received by the MFAF to one or more out-bound notification endpoints.'],\n",
       " 'category': ['Standards specifications'],\n",
       " 'option 5': [None],\n",
       " 'text': ['Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nWhat is the purpose of the Nmfaf_3daDataManagement_Deconfigure service operation? [3GPP Release 18]\\n\\n### Inputs:\\noption 1: To configure the MFAF to map data or analytics received by the MFAF to out-bound notification endpoints\\noption 2: To configure the MFAF to stop mapping data or analytics received by the MFAF to out-bound notification endpoints\\noption 3: To supply data or analytics from the MFAF to notification endpoints\\noption 4: To fetch data or analytics from the MFAF based on fetch instructions\\n\\n### Response:\\n']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context.\n",
      "\n",
      "### Instruction:\n",
      "Domain: Standards specifications:\n",
      "What is the purpose of the Nmfaf_3daDataManagement_Deconfigure service operation? [3GPP Release 18]\n",
      "\n",
      "### Inputs:\n",
      "option 1: To configure the MFAF to map data or analytics received by the MFAF to out-bound notification endpoints\n",
      "option 2: To configure the MFAF to stop mapping data or analytics received by the MFAF to out-bound notification endpoints\n",
      "option 3: To supply data or analytics from the MFAF to notification endpoints\n",
      "option 4: To fetch data or analytics from the MFAF based on fetch instructions\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_ds[:1][\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Below is an instruction that describes a task, paired with an input that provides further context.\n",
      "\n",
      "### Instruction:\n",
      "Domain: Standards specifications:\n",
      "What is the purpose of the Nmfaf_3daDataManagement_Deconfigure service operation? [3GPP Release 18]\n",
      "\n",
      "### Inputs:\n",
      "option 1: To configure the MFAF to map data or analytics received by the MFAF to out-bound notification endpoints\n",
      "option 2: To configure the MFAF to stop mapping data or analytics received by the MFAF to out-bound notification endpoints\n",
      "option 3: To supply data or analytics from the MFAF to notification endpoints\n",
      "option 4: To fetch data or analytics from the MFAF based on fetch instructions\n",
      "\n",
      "### Response:\n",
      "option 2: To configure the MFAF to stop mapping data or analytics received by the MFAF to out\n"
     ]
    }
   ],
   "source": [
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 25,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'option 3: If the cell is barred for connectivity to EPC'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "training_ds[[1000]][\"text\"], return_tensors = \"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "training_ds[1000][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Below is an instruction that describes a task, paired with an input that provides further context.\n",
      "\n",
      "### Instruction:\n",
      "Domain: Standards specifications:\n",
      "In the context of cell status and cell reservations, what does the field 'cellBarred' indicate? [3GPP Release 17]\n",
      "\n",
      "### Inputs:\n",
      "option 1: If the cell is barred for connectivity to 5GC\n",
      "option 2: If the cell is reserved for operator use\n",
      "option 3: If the cell is barred for connectivity to EPC\n",
      "option 4: If the cell supports network-based CRS interference mitigation\n",
      "option 5: If the cell is barred for emergency calls\n",
      "\n",
      "### Response:\n",
      "option 1: If the cell is barred for connectivity to 5GC\n",
      "\n",
      "### Instruction:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 25,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'option 5: To provide information such as data forwarding addresses and new SN security key.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "training_ds[[1200]][\"text\"], return_tensors = \"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "training_ds[1200][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Below is an instruction that describes a task, paired with an input that provides further context.\n",
      "\n",
      "### Instruction:\n",
      "Domain: Standards specifications:\n",
      "What is the purpose of the SGNB MODIFICATION REQUIRED message in the inter-gNB-DU mobility procedure using MCG SRB in EN-DC? [3GPP Release 17]\n",
      "\n",
      "### Inputs:\n",
      "option 1: To query the latest SCG configuration from the gNB-CU.\n",
      "option 2: To migrate the IPsec tunnels to new IP outer addresses.\n",
      "option 3: To perform RRC Connection Reconfiguration at the MeNB and UE.\n",
      "option 4: To configure BH RLC channels and BAP-layer route entries on the target path.\n",
      "option 5: To provide information such as data forwarding addresses and new SN security key.\n",
      "\n",
      "### Response:\n",
      "option 5: To provide information such as data forwarding addresses and new SN security key.\n",
      "\n",
      "### Instruction\n"
     ]
    }
   ],
   "source": [
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 25,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
