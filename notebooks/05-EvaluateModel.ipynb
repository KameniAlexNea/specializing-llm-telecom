{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "MODEL_PATH = \"data/models/All/checkpoint-2167\"\n",
    "TASK_ID = \"03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from peft import PeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "\n",
    "result: tuple[PeftModelForCausalLM, AutoTokenizer] = FastLanguageModel.from_pretrained(\n",
    "\tmodel_name = MODEL_PATH,\n",
    "\tmax_seq_length = max_seq_length,\n",
    "\tdtype = dtype,\n",
    "\tload_in_4bit = load_in_4bit,\n",
    "\t# token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")\n",
    "model: PeftModelForCausalLM = result[0]\n",
    "tokenizer: AutoTokenizer = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def create_dataset(data: dict):\n",
    "\tdef patch_raw(raw: dict):\n",
    "\t\tfor i in range(2, 6):\n",
    "\t\t\traw[f\"option {i}\"] = raw.get(f\"option {i}\")\n",
    "\t\treturn raw\n",
    "\tdata_pashed = [\n",
    "\t\tpatch_raw(raw) for raw in data.values()\n",
    "\t]\n",
    "\tdata_pashed = Dataset.from_list(data_pashed)\n",
    "\treturn data_pashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = json.load(open(\"data/zindi_data/TeleQnA_testing1.json\"))\n",
    "training_ds = create_dataset(training)\n",
    "\n",
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca_prompt = Copied from above\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I need you to choose the correct answer from a multiple-choice question. \n",
    "The question will have several options labeled with letters. There is always one correct answer among the choices. \n",
    "Please provide both the letter and the corresponding answer. \n",
    "Only generate the answer without any additional text.\n",
    "\"\"\"\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Inputs:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "OPTIONS = [f\"option {i}\" for i in range(1, 6)]\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples: dict[str, str]):\n",
    "\tdef apply_one(question,category, *options):\n",
    "\t\tinstructions = f\"Domain: {category}:\\n{question}\"\n",
    "\t\tinputs       = \"\\n\".join([f\"option {i}: \" + text for i, text in enumerate(options, start=1) if text is not None]) #  \n",
    "\t\toutputs      = \"\"\n",
    "\t\treturn alpaca_prompt.format(instructions, inputs, outputs)\n",
    "\ttexts = [apply_one(question, category, *options) for question, category, *options in zip(\n",
    "\t\texamples[\"question\"], examples[\"category\"], examples['option 1'], examples['option 2'], examples['option 3'], examples['option 4'], examples['option 5']\n",
    "\t)]\n",
    "\treturn {\"text\" : texts,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = training_ds.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds[:5][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "training_ds[:1][\"text\"], return_tensors = \"pt\", padding=True, truncation=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_ds[:1][\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.batch_decode(_)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "results = []\n",
    "for i in tqdm(range(0, len(training_ds), batch_size)):\n",
    "\traws = training_ds[i:i+batch_size]\n",
    "\tinputs = tokenizer(\n",
    "\t\traws[\"text\"], return_tensors = \"pt\", padding=True, truncation=True\n",
    "\t).to(\"cuda\")\n",
    "\ttexts_ids = model.generate(**inputs, max_new_tokens = 100,)\n",
    "\ttexts = tokenizer.batch_decode(texts_ids)\n",
    "\tresults.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_selected_response(text):\n",
    "    # Regex pattern to find the selected response in the template\n",
    "    pattern = r\"### Response:\\n(option \\d+: .+?)\\n\"\n",
    "\n",
    "    # Search for the pattern in the provided text\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_selected_response(results[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = list(map(extract_selected_response, results))\n",
    "responses[10:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = pd.Series([i for i in responses])\n",
    "\n",
    "responses_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df[responses_df.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.fillna(\"option 0:\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.apply(lambda x: str(x).startswith(\"option \")).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.str.split().apply(lambda x: int((x[1])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.str.split().apply(lambda x: int((x[1])[0])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_options = responses_df.str.split().apply(lambda x: int((x[1])[0]) - 1)\n",
    "\n",
    "selected_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([\n",
    "    selected_options.index, selected_options.values\n",
    "]).T, columns=[\"Question_ID\", \"Answer_ID\"])\n",
    "\n",
    "df[\"Task\"] = \"Phi-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"data/submission/{TASK_ID}-Phi_3_Model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
