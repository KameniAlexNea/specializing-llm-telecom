{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/eak/learning/llm_finetuning/specializing-llm-telecom\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from peft import PeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
      "   \\\\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.438 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.1+cu118. CUDA = 8.6. CUDA Toolkit = 11.8.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.26.post1+cu118. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "\n",
    "result: tuple[PeftModelForCausalLM, AutoTokenizer] = FastLanguageModel.from_pretrained(\n",
    "\tmodel_name = \"data/models/checkpoint-3750\",\n",
    "\tmax_seq_length = max_seq_length,\n",
    "\tdtype = dtype,\n",
    "\tload_in_4bit = load_in_4bit,\n",
    "\t# token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")\n",
    "model: PeftModelForCausalLM = result[0]\n",
    "tokenizer: AutoTokenizer = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def create_dataset(data: dict):\n",
    "\tdef patch_raw(raw: dict):\n",
    "\t\tfor i in range(2, 6):\n",
    "\t\t\traw[f\"option {i}\"] = raw.get(f\"option {i}\")\n",
    "\t\treturn raw\n",
    "\tdata_pashed = [\n",
    "\t\tpatch_raw(raw) for raw in data.values()\n",
    "\t]\n",
    "\tdata_pashed = Dataset.from_list(data_pashed)\n",
    "\treturn data_pashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = json.load(open(\"data/zindi_data/TeleQnA_testing1.json\"))\n",
    "training_ds = create_dataset(training)\n",
    "\n",
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca_prompt = Copied from above\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I need you to choose the correct answer from a multiple-choice question. \n",
    "The question will have several options labeled with letters. There is always one correct answer among the choices. \n",
    "Please provide both the letter and the corresponding answer. \n",
    "Only generate the answer without any additional text.\n",
    "\"\"\"\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Inputs:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "OPTIONS = [f\"option {i}\" for i in range(1, 6)]\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples: dict[str, str]):\n",
    "\tdef apply_one(question,category, *options):\n",
    "\t\tinstructions = f\"Domain: {category}:\\n{question}\"\n",
    "\t\tinputs       = \"\\n\".join([f\"option {i}: \" + text for i, text in enumerate(options, start=1) if text is not None]) #  \n",
    "\t\toutputs      = \"\"\n",
    "\t\treturn alpaca_prompt.format(instructions, inputs, outputs)\n",
    "\ttexts = [apply_one(question, category, *options) for question, category, *options in zip(\n",
    "\t\texamples[\"question\"], examples[\"category\"], examples['option 1'], examples['option 2'], examples['option 3'], examples['option 4'], examples['option 5']\n",
    "\t)]\n",
    "\treturn {\"text\" : texts,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c64f9c90614a5cb02c067ade2eac06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/366 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_ds = training_ds.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nWhen can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]\\n\\n### Inputs:\\noption 1: Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.\\noption 2: If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\\noption 3: Both option 1 and option 2\\noption 4: None of the above\\n\\n### Response:\\n',\n",
       " \"Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nWhat does OTA REFSENS requirement ensure? [3GPP Release 18]\\n\\n### Inputs:\\noption 1: The accuracy of the receiver in filtering out out-of-band signals.\\noption 2: The ability of the receiver to receive a wanted signal in the presence of an interfering signal.\\noption 3: The receiver's ability to receive an unwanted signal in the presence of a wanted signal.\\noption 4: The accuracy of the receiver in filtering out adjacent channel signals.\\noption 5: The minimum mean power received at the RIB for a specified reference measurement channel.\\n\\n### Response:\\n\",\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nWhat is the role of MDA MnS producer in the management function? [3GPP Release 17]\\n\\n### Inputs:\\noption 1: Producer of NWDAF data\\noption 2: Consumer of MDA reports\\noption 3: Producer of MDA reports\\noption 4: Consumer of NWDAF data\\noption 5: Producer of RAN control data\\n\\n### Response:\\n',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nWhat type of subcarrier spacing requirements does an NB-IoT Base Station support? [3GPP Release 18]\\n\\n### Inputs:\\noption 1: 15 kHz subcarrier spacing requirements only\\noption 2: 3.75 kHz subcarrier spacing requirements only\\noption 3: Both 15 kHz and 3.75 kHz subcarrier spacing requirements\\noption 4: No subcarrier spacing requirements\\n\\n### Response:\\n',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nWhat is the purpose of the IAB-node OAM procedure? [3GPP Release 17]\\n\\n### Inputs:\\noption 1: To activate and deactivate UE traces in the gNB-DU and the gNB-CU-UP\\noption 2: To handle the release of an IAB-node in an orderly fashion\\noption 3: To allocate IP addresses for IAB-nodes\\noption 4: To exchange commands, configuration data, and software downloads between the IAB-node and its OAM system\\n\\n### Response:\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds[:5][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "training_ds[:1][\"text\"], return_tensors = \"pt\", padding=True, truncation=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ['When can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]'],\n",
       " 'option 1': ['Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.'],\n",
       " 'option 2': ['If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.'],\n",
       " 'option 3': ['Both option 1 and option 2'],\n",
       " 'option 4': ['None of the above'],\n",
       " 'category': ['Standards specifications'],\n",
       " 'option 5': [None],\n",
       " 'text': ['Below is an instruction that describes a task, paired with an input that provides further context.\\n\\n### Instruction:\\nDomain: Standards specifications:\\nWhen can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]\\n\\n### Inputs:\\noption 1: Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.\\noption 2: If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\\noption 3: Both option 1 and option 2\\noption 4: None of the above\\n\\n### Response:\\n']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context.\n",
      "\n",
      "### Instruction:\n",
      "Domain: Standards specifications:\n",
      "When can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]\n",
      "\n",
      "### Inputs:\n",
      "option 1: Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.\n",
      "option 2: If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\n",
      "option 3: Both option 1 and option 2\n",
      "option 4: None of the above\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_ds[:1][\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Below is an instruction that describes a task, paired with an input that provides further context.\n",
      "\n",
      "### Instruction:\n",
      "Domain: Standards specifications:\n",
      "When can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]\n",
      "\n",
      "### Inputs:\n",
      "option 1: Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.\n",
      "option 2: If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\n",
      "option 3: Both option 1 and option 2\n",
      "option 4: None of the above\n",
      "\n",
      "### Response:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option 3: Both option 1 and option 2\n",
      "\n",
      "### Instruction:\n",
      "What is the purpose of the UE-id field in the DMG protected PPDU?\n",
      "\n",
      "### Inputs:\n",
      "option 1: To identify the DL RS for which the DMG protected PPDU applies.\n",
      "option 2: To identify the UE to which the DMG protected PPDU applies.\n",
      "option 3: To indicate the number of DM\n"
     ]
    }
   ],
   "source": [
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Below is an instruction that describes a task, paired with an input that provides further context.\n",
      "\n",
      "### Instruction:\n",
      "Domain: Standards specifications:\n",
      "When can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]\n",
      "\n",
      "### Inputs:\n",
      "option 1: Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.\n",
      "option 2: If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\n",
      "option 3: Both option 1 and option 2\n",
      "option 4: None of the above\n",
      "\n",
      "### Response:\n",
      "option 3: Both option 1 and option 2\n",
      "\n",
      "### Instruction:\n",
      "What is the purpose of the UE-id field in the DMG protected PPDU?\n",
      "\n",
      "### Inputs:\n",
      "option 1: To identify the DL RS for which the DMG protected PPDU applies.\n",
      "option 2: To identify the UE to which the DMG protected PPDU applies.\n",
      "option 3: To indicate the number of DM\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(_)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [04:38<00:00,  6.06s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "results = []\n",
    "for i in tqdm(range(0, len(training_ds), batch_size)):\n",
    "\traws = training_ds[i:i+batch_size]\n",
    "\tinputs = tokenizer(\n",
    "\t\traws[\"text\"], return_tensors = \"pt\", padding=True, truncation=True\n",
    "\t).to(\"cuda\")\n",
    "\ttexts_ids = model.generate(**inputs, max_new_tokens = 100,)\n",
    "\ttexts = tokenizer.batch_decode(texts_ids)\n",
    "\tresults.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><|placeholder6|><s> Below is an instruction that describes a task, paired with an input that provides further context.\n",
      "\n",
      "### Instruction:\n",
      "Domain: Standards specifications:\n",
      "What is the cardinality rule for EECs? [3GPP Release 18]\n",
      "\n",
      "### Inputs:\n",
      "option 1: One or more EEC(s) may be located in a UE\n",
      "option 2: One or more EEC(s) may be located in an EDN\n",
      "option 3: One or more EEC(s) may be deployed to support one EDN\n",
      "option 4: One or more EEC(s) may be deployed by a PLMN operator\n",
      "\n",
      "### Response:\n",
      "option 3: One or more EEC(s) may be deployed to support one EDN\n",
      "\n",
      "### Instruction:\n",
      "What is the purpose of the EEC Configuration Information? [3GPP Release 18]\n",
      "\n",
      "### Inputs:\n",
      "option 1: To provide information about the EECs deployed by a PLMN operator\n",
      "option 2: To provide information about the EDNs supported by a PLMN operator\n",
      "option 3:\n"
     ]
    }
   ],
   "source": [
    "print(results[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_selected_response(text):\n",
    "    # Regex pattern to find the selected response in the template\n",
    "    pattern = r\"### Response:\\n(option \\d+: .+?)\\n\"\n",
    "\n",
    "    # Search for the pattern in the provided text\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option 3: One or more EEC(s) may be deployed to support one EDN\n"
     ]
    }
   ],
   "source": [
    "print(extract_selected_response(results[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['option 3: One or more EEC(s) may be deployed to support one EDN',\n",
       " 'option 4: Random access related procedures',\n",
       " 'option 1: 95% of the maximum throughput of the reference measurement channel.',\n",
       " 'option 3: The NR RRC information used by the target gNB during handover preparation or UE context retrieval',\n",
       " 'option 3: 15',\n",
       " 'option 2: To reduce the number of PC1 TRP grid points']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = list(map(extract_selected_response, results))\n",
    "responses[10:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241                    option 5: Charging Function (CHF)\n",
       "348                  option 4: Composite rotation matrix\n",
       "126    option 5: To allow UEs to use direct device co...\n",
       "32                                   option 1: TS 36.331\n",
       "289    option 2: PLMN selection, cell selection and r...\n",
       "123                         option 1: Gi reference point\n",
       "310    option 1: DNN, S-NSSAI, and Maximum Group Data...\n",
       "264         option 3: Signaling of its LHN ID to the MME\n",
       "166    option 3: Semi-static CFI configuration, PDSCH...\n",
       "328    option 2: Same slot and symbol for PRS resourc...\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df = pd.Series([i for i in responses])\n",
    "\n",
    "responses_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df[responses_df.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      5\n",
       "2      3\n",
       "3      3\n",
       "4      4\n",
       "      ..\n",
       "361    3\n",
       "362    1\n",
       "363    1\n",
       "364    1\n",
       "365    2\n",
       "Length: 366, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df.str.split().apply(lambda x: int((x[1])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    85\n",
       "3    84\n",
       "2    69\n",
       "4    68\n",
       "5    60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df.str.split().apply(lambda x: int((x[1])[0])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      4\n",
       "2      2\n",
       "3      2\n",
       "4      3\n",
       "      ..\n",
       "361    2\n",
       "362    0\n",
       "363    0\n",
       "364    0\n",
       "365    1\n",
       "Length: 366, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_options = responses_df.str.split().apply(lambda x: int((x[1])[0]) - 1)\n",
    "\n",
    "selected_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([\n",
    "    selected_options.index, selected_options.values\n",
    "]).T, columns=[\"Question_ID\", \"Answer_ID\"])\n",
    "\n",
    "df[\"Task\"] = \"Phi-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_ID</th>\n",
       "      <th>Answer_ID</th>\n",
       "      <th>Task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Phi-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Phi-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Phi-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Phi-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Phi-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>Phi-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "      <td>Phi-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>Phi-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>Phi-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>Phi-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Question_ID  Answer_ID   Task\n",
       "0              0          2  Phi-3\n",
       "1              1          4  Phi-3\n",
       "2              2          2  Phi-3\n",
       "3              3          2  Phi-3\n",
       "4              4          3  Phi-3\n",
       "..           ...        ...    ...\n",
       "361          361          2  Phi-3\n",
       "362          362          0  Phi-3\n",
       "363          363          0  Phi-3\n",
       "364          364          0  Phi-3\n",
       "365          365          1  Phi-3\n",
       "\n",
       "[366 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/submission/01-Phi_3_Model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
