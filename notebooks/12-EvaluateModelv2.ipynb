{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/eak/learning/llm_finetuning/specializing-llm-telecom\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "# os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "MODEL_PATH = \"data/models/generated/checkpoint-8000\"\n",
    "TASK_ID = \"04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from peft import PeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Mistral patching release 2024.6\n",
      "   \\\\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.438 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.1.1+cu118. CUDA = 8.6. CUDA Toolkit = 11.8.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.23+cu118. FA = False.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Unsloth 2024.6 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "\n",
    "result: tuple[PeftModelForCausalLM, AutoTokenizer] = FastLanguageModel.from_pretrained(\n",
    "\tmodel_name = MODEL_PATH,\n",
    "\tmax_seq_length = max_seq_length,\n",
    "\tdtype = dtype,\n",
    "\tload_in_4bit = load_in_4bit,\n",
    "\t# token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")\n",
    "model: PeftModelForCausalLM = result[0]\n",
    "tokenizer: AutoTokenizer = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def create_dataset(data: dict):\n",
    "\tdef patch_raw(raw: dict):\n",
    "\t\tfor i in range(2, 6):\n",
    "\t\t\traw[f\"option {i}\"] = raw.get(f\"option {i}\")\n",
    "\t\treturn raw\n",
    "\tdata_pashed = [\n",
    "\t\tpatch_raw(raw) for raw in data.values()\n",
    "\t]\n",
    "\tdata_pashed = Dataset.from_list(data_pashed)\n",
    "\treturn data_pashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = json.load(open(\"data/zindi_data/TeleQnA_testing1.json\"))\n",
    "training_ds = create_dataset(training)\n",
    "\n",
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca_prompt = Copied from above\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"You are an AI assistant specialized in the 3rd Generation Partnership Project (3GPP) Release specifications. The Standards Development: 3GPP is known for creating standards for 3G (third generation), 4G (fourth generation), and 5G (fifth generation) mobile networks. \n",
    "Your task is to analyze questions and select the most appropriate answer from given options based on your knowledge of 3GPP standards.\n",
    "\n",
    "<instruction>\n",
    "{}\n",
    "</instruction>\n",
    "\n",
    "<options>\n",
    "{}\n",
    "</options>\n",
    "\n",
    "<reponse>\"\"\"\n",
    "\n",
    "OPTIONS = [f\"option {i}\" for i in range(1, 6)]\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples: dict[str, str]):\n",
    "\tdef apply_one(question, *options):\n",
    "\t\tinstructions = f\"{question}\"\n",
    "\t\tinputs       = \"\\n\".join([f\"option {i}: \" + text for i, text in enumerate(options, start=1) if text is not None]) # \n",
    "\t\treturn alpaca_prompt.format(instructions, inputs)\n",
    "\ttexts = [apply_one(question, *options) for question, *options in zip(\n",
    "\t\texamples[\"question\"], examples['option 1'], examples['option 2'], examples['option 3'], examples['option 4'], examples['option 5']\n",
    "\t)]\n",
    "\treturn {\"text\" : texts,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe86ea3631249e398f44bada0c501a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/366 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_ds = training_ds.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You are an AI assistant specialized in the 3rd Generation Partnership Project (3GPP) Release specifications. The Standards Development: 3GPP is known for creating standards for 3G (third generation), 4G (fourth generation), and 5G (fifth generation) mobile networks. \\nYour task is to analyze questions and select the most appropriate answer from given options based on your knowledge of 3GPP standards.\\n\\n<instruction>\\nWhen can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]\\n</instruction>\\n\\n<options>\\noption 1: Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.\\noption 2: If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\\noption 3: Both option 1 and option 2\\noption 4: None of the above\\n</options>\\n\\n<reponse>',\n",
       " \"You are an AI assistant specialized in the 3rd Generation Partnership Project (3GPP) Release specifications. The Standards Development: 3GPP is known for creating standards for 3G (third generation), 4G (fourth generation), and 5G (fifth generation) mobile networks. \\nYour task is to analyze questions and select the most appropriate answer from given options based on your knowledge of 3GPP standards.\\n\\n<instruction>\\nWhat does OTA REFSENS requirement ensure? [3GPP Release 18]\\n</instruction>\\n\\n<options>\\noption 1: The accuracy of the receiver in filtering out out-of-band signals.\\noption 2: The ability of the receiver to receive a wanted signal in the presence of an interfering signal.\\noption 3: The receiver's ability to receive an unwanted signal in the presence of a wanted signal.\\noption 4: The accuracy of the receiver in filtering out adjacent channel signals.\\noption 5: The minimum mean power received at the RIB for a specified reference measurement channel.\\n</options>\\n\\n<reponse>\",\n",
       " 'You are an AI assistant specialized in the 3rd Generation Partnership Project (3GPP) Release specifications. The Standards Development: 3GPP is known for creating standards for 3G (third generation), 4G (fourth generation), and 5G (fifth generation) mobile networks. \\nYour task is to analyze questions and select the most appropriate answer from given options based on your knowledge of 3GPP standards.\\n\\n<instruction>\\nWhat is the role of MDA MnS producer in the management function? [3GPP Release 17]\\n</instruction>\\n\\n<options>\\noption 1: Producer of NWDAF data\\noption 2: Consumer of MDA reports\\noption 3: Producer of MDA reports\\noption 4: Consumer of NWDAF data\\noption 5: Producer of RAN control data\\n</options>\\n\\n<reponse>',\n",
       " 'You are an AI assistant specialized in the 3rd Generation Partnership Project (3GPP) Release specifications. The Standards Development: 3GPP is known for creating standards for 3G (third generation), 4G (fourth generation), and 5G (fifth generation) mobile networks. \\nYour task is to analyze questions and select the most appropriate answer from given options based on your knowledge of 3GPP standards.\\n\\n<instruction>\\nWhat type of subcarrier spacing requirements does an NB-IoT Base Station support? [3GPP Release 18]\\n</instruction>\\n\\n<options>\\noption 1: 15 kHz subcarrier spacing requirements only\\noption 2: 3.75 kHz subcarrier spacing requirements only\\noption 3: Both 15 kHz and 3.75 kHz subcarrier spacing requirements\\noption 4: No subcarrier spacing requirements\\n</options>\\n\\n<reponse>',\n",
       " 'You are an AI assistant specialized in the 3rd Generation Partnership Project (3GPP) Release specifications. The Standards Development: 3GPP is known for creating standards for 3G (third generation), 4G (fourth generation), and 5G (fifth generation) mobile networks. \\nYour task is to analyze questions and select the most appropriate answer from given options based on your knowledge of 3GPP standards.\\n\\n<instruction>\\nWhat is the purpose of the IAB-node OAM procedure? [3GPP Release 17]\\n</instruction>\\n\\n<options>\\noption 1: To activate and deactivate UE traces in the gNB-DU and the gNB-CU-UP\\noption 2: To handle the release of an IAB-node in an orderly fashion\\noption 3: To allocate IP addresses for IAB-nodes\\noption 4: To exchange commands, configuration data, and software downloads between the IAB-node and its OAM system\\n</options>\\n\\n<reponse>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds[:5][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "training_ds[:1][\"text\"], return_tensors = \"pt\", padding=True, truncation=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ['When can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]'],\n",
       " 'option 1': ['Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.'],\n",
       " 'option 2': ['If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.'],\n",
       " 'option 3': ['Both option 1 and option 2'],\n",
       " 'option 4': ['None of the above'],\n",
       " 'category': ['Standards specifications'],\n",
       " 'option 5': [None],\n",
       " 'text': ['You are an AI assistant specialized in the 3rd Generation Partnership Project (3GPP) Release specifications. The Standards Development: 3GPP is known for creating standards for 3G (third generation), 4G (fourth generation), and 5G (fifth generation) mobile networks. \\nYour task is to analyze questions and select the most appropriate answer from given options based on your knowledge of 3GPP standards.\\n\\n<instruction>\\nWhen can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]\\n</instruction>\\n\\n<options>\\noption 1: Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.\\noption 2: If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\\noption 3: Both option 1 and option 2\\noption 4: None of the above\\n</options>\\n\\n<reponse>']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI assistant specialized in the 3rd Generation Partnership Project (3GPP) Release specifications. The Standards Development: 3GPP is known for creating standards for 3G (third generation), 4G (fourth generation), and 5G (fifth generation) mobile networks. \n",
      "Your task is to analyze questions and select the most appropriate answer from given options based on your knowledge of 3GPP standards.\n",
      "\n",
      "<instruction>\n",
      "When can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]\n",
      "</instruction>\n",
      "\n",
      "<options>\n",
      "option 1: Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.\n",
      "option 2: If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\n",
      "option 3: Both option 1 and option 2\n",
      "option 4: None of the above\n",
      "</options>\n",
      "\n",
      "<reponse>\n"
     ]
    }
   ],
   "source": [
    "print(training_ds[:1][\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI assistant specialized in the 3rd Generation Partnership Project (3GPP) Release specifications. The Standards Development: 3GPP is known for creating standards for 3G (third generation), 4G (fourth generation), and 5G (fifth generation) mobile networks. \n",
      "Your task is to analyze questions and select the most appropriate answer from given options based on your knowledge of 3GPP standards.\n",
      "\n",
      "<instruction>\n",
      "When can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]\n",
      "</instruction>\n",
      "\n",
      "<options>\n",
      "option 1: Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.\n",
      "option 2: If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\n",
      "option 3: Both option 1 and option 2\n",
      "option 4: None of the above\n",
      "</options>\n",
      "\n",
      "<reponse>\n",
      "option 3: Both option 1 and option 2\n",
      "</reponse>\n",
      "\n",
      "<explanation>\n",
      "A gNB can transmit a DL transmission(s) on a channel after initiating a channel occupancy if the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\n",
      "</explanation>\n",
      "\n",
      "<unsupported>\n",
      "option 4\n"
     ]
    }
   ],
   "source": [
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI assistant specialized in the 3rd Generation Partnership Project (3GPP) Release specifications. The Standards Development: 3GPP is known for creating standards for 3G (third generation), 4G (fourth generation), and 5G (fifth generation) mobile networks. \n",
      "Your task is to analyze questions and select the most appropriate answer from given options based on your knowledge of 3GPP standards.\n",
      "\n",
      "<instruction>\n",
      "When can a gNB transmit a DL transmission(s) on a channel after initiating a channel occupancy? [3GPP Release 17]\n",
      "</instruction>\n",
      "\n",
      "<options>\n",
      "option 1: Regardless of the duration of the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB.\n",
      "option 2: If the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\n",
      "option 3: Both option 1 and option 2\n",
      "option 4: None of the above\n",
      "</options>\n",
      "\n",
      "<reponse>\n",
      "option 3: Both option 1 and option 2\n",
      "</reponse>\n",
      "\n",
      "<explanation>\n",
      "A gNB can transmit a DL transmission(s) on a channel after initiating a channel occupancy if the gap between the DL transmission(s) and any previous transmission(s) corresponding to the channel occupancy initiated by the gNB is more than a threshold.\n",
      "</explanation>\n",
      "\n",
      "<unsupported>\n",
      "option 4\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(_)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 7/46 [00:40<03:40,  5.66s/it]"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "results = []\n",
    "for i in tqdm(range(0, len(training_ds), batch_size)):\n",
    "\traws = training_ds[i:i+batch_size]\n",
    "\tinputs = tokenizer(\n",
    "\t\traws[\"text\"], return_tensors = \"pt\", padding=True, truncation=True\n",
    "\t).to(\"cuda\")\n",
    "\ttexts_ids = model.generate(**inputs, max_new_tokens = 100,)\n",
    "\ttexts = tokenizer.batch_decode(texts_ids)\n",
    "\tresults.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_selected_response(text):\n",
    "    # Regex pattern to find the selected response in the template\n",
    "    pattern = r\"<reponse>\\n(option \\d+: .+?)\\n\"\n",
    "\n",
    "    # Search for the pattern in the provided text\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_selected_response(results[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = list(map(extract_selected_response, results))\n",
    "responses[10:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = pd.Series([i for i in responses])\n",
    "\n",
    "responses_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df[responses_df.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(responses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.fillna(\"option 0:\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.apply(lambda x: str(x).startswith(\"option \")).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.str.split().apply(lambda x: int((x[1])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.str.split().apply(lambda x: int((x[1])[0])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_options = responses_df.str.split().apply(lambda x: int((x[1])[0]) - 1)\n",
    "\n",
    "selected_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([\n",
    "    selected_options.index, selected_options.values\n",
    "]).T, columns=[\"Question_ID\", \"Answer_ID\"])\n",
    "\n",
    "df[\"Task\"] = \"Phi-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"data/submission/{TASK_ID}-Phi_3_Generated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"data/submission/{TASK_ID}-Phi_3_Generated.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
